{
  "name": "Workflow with Chat Memory and Vector Store as tool.",
  "nodes": [
    {
      "parameters": {
        "content": "## 1. Download & Extract Internal Policy Documents\n[Read more about the HTTP Request Tool](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\n\nBegin by importing the PDF documents that contain your internal policies and FAQs—these will become the knowledge base for your Internal Helpdesk Assistant. For example, you can store a company handbook or IT/HR policy PDFs on a shared drive or cloud storage and reference a direct download link here.\n\nIn this demonstration, we'll use the **HTTP Request node** to fetch the PDF file from a given URL and then parse its text contents using the **Extract from File node**. Once extracted, these text chunks will be used to build the vector store that underpins your helpdesk chatbot’s responses.\n\n[Example Employee Handbook with Policies](https://s3.amazonaws.com/scschoolfiles/656/employee_handbook_print_1.pdf)",
        "height": 480,
        "width": 780,
        "color": 7
      },
      "id": "aca5cd5b-6f1f-48d6-80bf-0da9122f7b10",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -300,
        -280
      ],
      "typeVersion": 1
    },
    {
      "parameters": {},
      "id": "2c854275-6090-4347-9690-60dcabf68e66",
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "position": [
        -80,
        20
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "url": "https://s3.amazonaws.com/scschoolfiles/656/employee_handbook_print_1.pdf",
        "options": {}
      },
      "id": "a434f217-0245-45f8-91cc-a5adc66769a6",
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        100,
        20
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "operation": "pdf",
        "options": {
          "maxPages": 2
        }
      },
      "id": "ea502c8f-3c50-4a1e-89c4-6dbf874ba6b6",
      "name": "Extract from File",
      "type": "n8n-nodes-base.extractFromFile",
      "position": [
        280,
        20
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## 2. Create Internal Policy Vector Store\n[Read more about the In-Memory Vector Store](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/)\n\nVector stores power the retrieval process by matching a user's natural language questions to relevant chunks of text. We'll transform your extracted internal policy text into vector embeddings and store them in a database-like structure.\n\nWe will be using Neo4j which has production ready vector support.\n\n**How it works**  \n1. The text extracted in Step 1 is split into manageable segments (chunks).  \n2. An embedding model transforms these segments into numerical vectors.  \n3. These vectors, along with metadata, are stored in Neo4j.  \n4. When users ask a question, their query is embedded and matched to the most relevant vectors, improving the accuracy of the chatbot's response.",
        "height": 1020,
        "width": 780,
        "color": 7
      },
      "id": "db36faf8-6ab9-4690-ade7-87655dca9e9b",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        540,
        -280
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "jsonMode": "expressionData",
        "jsonData": "={{ $('Extract from File').item.json.text }}",
        "options": {}
      },
      "id": "c1c5e772-44d5-4c4e-8075-e3382e476d2b",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "position": [
        900,
        340
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "chunkSize": 2000,
        "options": {}
      },
      "id": "d55e4b66-2928-4e5b-8e34-4da053ed8b94",
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "position": [
        840,
        520
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "You are a helpful assistant for HR and employee policies"
        }
      },
      "id": "382114d2-ed43-48e8-a847-353f3bfcacb8",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        2080,
        420
      ],
      "typeVersion": 1.7
    },
    {
      "parameters": {
        "name": "hr_employee_policies",
        "description": "data for HR and employee policies"
      },
      "id": "b5a95e27-1822-49ae-80b7-bc017a110aac",
      "name": "Answer questions with a vector store",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "position": [
        2580,
        600
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "The setup needs to be run at the start or when data is changed",
        "height": 80,
        "width": 260
      },
      "id": "f5e455f9-3c09-46d0-8639-8a582a8b1569",
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        220,
        240
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## 3. Handling Messages and HR & IT AI Agent Provides Helpdesk Support  \nn8n's AI agents allow you to create intelligent and interactive workflows that can access and retrieve data from internal knowledgebases. In this workflow, the AI agent is configured to provide answers for HR and IT queries by performing Retrieval-Augmented Generation (RAG) on internal documents.\n\n### How It Works:\n- type a message, e.g `What are the company's sick leave policies?`\n- **Internal Knowledgebase Access**: A **Vector store tool** is used to connect the agent to the HR & IT knowledgebase built earlier in the workflow. This enables the agent to fetch accurate and specific answers for employee queries.\n- **Chat Memory**: A **Chat memory subnode** tracks the conversation, allowing the agent to maintain context across multiple queries from the same user, creating a personalized and cohesive experience.\n- **Dynamic Query Responses**: Whether employees ask about policies, leave balances, or technical troubleshooting, the agent retrieves relevant data from the vector store and crafts a natural language response.\n\nBy integrating the AI agent with a vector store and chat memory, this workflow empowers your HR & IT helpdesk chatbot to provide quick, accurate, and conversational support to employees. \n\nPostgrSQL is used for all steps to simplify development in production.",
        "height": 1420,
        "width": 1640,
        "color": 4
      },
      "id": "826c730e-ea8e-4ecf-bc2c-d2f2165bf25f",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1440,
        -260
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## 4. Save results\n\nSave results in CSV file named chatEmbedding.csv",
        "height": 360,
        "width": 740,
        "color": 4
      },
      "id": "f79eac5b-f458-4851-b064-b55eafaafbf9",
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3120,
        320
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "model": "qwen2.5:latest"
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "typeVersion": 1,
      "position": [
        600,
        400
      ],
      "id": "2d0be610-5db6-40f8-b90b-21441ca32340",
      "name": "Embeddings Ollama",
      "credentials": {
        "ollamaApi": {
          "id": "BOUWJuC5zIYjUeue",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        1600,
        400
      ],
      "id": "7d360eb1-6d16-4d9a-9857-5799a1a18a36",
      "name": "When chat message received",
      "webhookId": "4572d973-a304-40db-aaee-929209439b2a"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [
        3260,
        440
      ],
      "id": "fe79f1d2-363a-4c8b-b076-de49d576a193",
      "name": "Convert to File"
    },
    {
      "parameters": {
        "model": "qwen2.5:latest",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        1960,
        740
      ],
      "id": "e2ece311-2d29-4d46-bf1d-0549f0294363",
      "name": "Ollama Chat Model",
      "credentials": {
        "ollamaApi": {
          "id": "BOUWJuC5zIYjUeue",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "customSession"
      },
      "type": "CUSTOM.memoryNeo4jChat",
      "typeVersion": 1,
      "position": [
        2180,
        780
      ],
      "id": "50fdf2b4-ca4a-438c-a1e7-860e89fa13fb",
      "name": "Neo4j Chat Memory",
      "credentials": {
        "neo4j": {
          "id": "52pmHFYBBzuOvaOb",
          "name": "Neo4j Credentials account"
        }
      }
    },
    {
      "parameters": {
        "model": "qwen2.5:latest",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        2840,
        820
      ],
      "id": "ee68fbe8-5605-4e2c-8dd9-4d8fa346fb3c",
      "name": "Ollama Chat Model1",
      "credentials": {
        "ollamaApi": {
          "id": "BOUWJuC5zIYjUeue",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "model": "qwen2.5:latest"
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "typeVersion": 1,
      "position": [
        2540,
        1000
      ],
      "id": "a672e7b7-915d-4a3e-953f-bc372e94f58c",
      "name": "Embeddings Ollama1",
      "credentials": {
        "ollamaApi": {
          "id": "BOUWJuC5zIYjUeue",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "operation": "write",
        "fileName": "/home/node/chatEmbedding.csv",
        "options": {}
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        3500,
        440
      ],
      "id": "7ae2738a-f380-49ff-beb1-9095fed08663",
      "name": "Read/Write Files from Disk"
    },
    {
      "parameters": {
        "mode": "insert",
        "label": "DocumentPdf",
        "indexName": "vector_pdf",
        "embedding": "embedding_pdf"
      },
      "type": "CUSTOM.vectorStoreNeo4j",
      "typeVersion": 1.1,
      "position": [
        700,
        100
      ],
      "id": "9791198c-93f7-448d-8946-e832f9481855",
      "name": "Neo4j Vector Store populate",
      "credentials": {
        "neo4j": {
          "id": "52pmHFYBBzuOvaOb",
          "name": "Neo4j Credentials account"
        }
      }
    },
    {
      "parameters": {
        "label": "DocumentPdf",
        "indexName": "vector_pdf",
        "embedding": "embedding_pdf"
      },
      "type": "CUSTOM.vectorStoreNeo4j",
      "typeVersion": 1.1,
      "position": [
        2440,
        780
      ],
      "id": "2f2d9ad6-f399-4896-9da4-bb925d30501b",
      "name": "Neo4j Vector Store retrieve",
      "credentials": {
        "neo4j": {
          "id": "52pmHFYBBzuOvaOb",
          "name": "Neo4j Credentials account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "AI Agent": {
      "main": [
        [
          {
            "node": "Convert to File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request": {
      "main": [
        [
          {
            "node": "Extract from File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File": {
      "main": [
        [
          {
            "node": "Neo4j Vector Store populate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Neo4j Vector Store populate",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Recursive Character Text Splitter": {
      "ai_textSplitter": [
        [
          {
            "node": "Default Data Loader",
            "type": "ai_textSplitter",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Test workflow’": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Answer questions with a vector store": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Ollama": {
      "ai_embedding": [
        [
          {
            "node": "Neo4j Vector Store populate",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Neo4j Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Answer questions with a vector store",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Ollama1": {
      "ai_embedding": [
        [
          {
            "node": "Neo4j Vector Store retrieve",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Convert to File": {
      "main": [
        [
          {
            "node": "Read/Write Files from Disk",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Neo4j Vector Store retrieve": {
      "ai_vectorStore": [
        [
          {
            "node": "Answer questions with a vector store",
            "type": "ai_vectorStore",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "f68671c7-c632-4b0c-ae7a-5e9f7deb86f5",
  "meta": {
    "instanceId": "558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a",
    "templateCredsSetupCompleted": true
  },
  "id": "adYVK8YgDDszqcEf",
  "tags": []
}